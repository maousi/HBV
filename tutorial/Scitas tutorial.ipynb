{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Deneb is a cluster among others.\n",
    "\n",
    "See the documentation https://scitas-data.epfl.ch/kb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared storage\n",
    "\n",
    "## Cluster\n",
    "\n",
    "### /scratch\n",
    "* high performance **temporary space**\n",
    "* not backed up\n",
    "* local to each cluster\n",
    "* disposable files: intermediate results, temporary files\n",
    "* automatical deletion of files older than 2 weeks (or when high occupancy)\n",
    "\n",
    "## Global\n",
    "\n",
    "### /home\n",
    "\n",
    "* 100Gb per user\n",
    "* backed up to a remote site\n",
    "* available on all clusters\n",
    "* for important files: source code, final results\n",
    "\n",
    "### /work\n",
    "\n",
    "* per group quotas\n",
    "* 50Gb for free\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands\n",
    "\n",
    "Connect\n",
    "\n",
    "    ssh username@deneb1.epf.ch\n",
    "    \n",
    "Basic commands\n",
    "    \n",
    "    id\n",
    "    pwd\n",
    "    ls /scratch/<username>\n",
    "    cd /scratch/<username>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch vs Interactive\n",
    "\n",
    "* Interactive : open software and work\n",
    "* Bash: script the work to be done, put it in queue. \n",
    "* Schedulers: decide when and where to run the job (depending on the requested resources and priority)\n",
    "\n",
    "### sbatch\n",
    "\n",
    "`sbatch` is the fundamental command to submit jobs. Workflow:\n",
    "\n",
    "1. create a job-script\n",
    "1. submit it to the batch system\n",
    "1. *gets executed at some point*\n",
    "1. look at the output\n",
    "\n",
    "### Interactive access\n",
    "\n",
    "* `salloc`: standard tool for interactive allocation for multi-node jovs\n",
    "* `Sinteract`: custom tool to access a node\n",
    "\n",
    "Behind the scenes, both use the same machanism as `sbatch` to get access to resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancelling jobs\n",
    "\n",
    "* Specific job: `scancel <JOB_ID>`\n",
    "* All jobs: `scancel -u <username>`\n",
    "* All jobs that are not yet running: `scancel -u <username> -t PENDING`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List queues\n",
    "\n",
    "`squeue` without arguments lists all jobs currently in the queue. `Squeue` is a custom squeue showing only your jobs with useful information \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S tools\n",
    "\n",
    "* `Sinteract`: custom tool to access a node\n",
    "* `Sshare`: show fairshare information\n",
    "* `Squeue`: show your pending and running jobs\n",
    "* `Sjob`: show information about a job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitions\n",
    "\n",
    "* debug: `--partition=debug` or `Sinteract -p debug`\n",
    "* build: `Sinteract -p build`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLURM directives\n",
    "\n",
    "`#SBATCH--something` is how to tell SLURM the required resources. \n",
    "\n",
    "* Number of nodes per job: `--nodes XX`. Default is 1.\n",
    "* Number of MPI tasks per job: `--ntasks XX`. Default is 1.\n",
    "* Number of CPUs per task (multithreaded apps): `--cpu-per-task XX`. Default is 1. Can't be greater than the number of cores/cpus in a compute node. \n",
    "* Memory per node: `--mem 120G`, `--mem 4096M`. Default is 4096MB per CPU.\n",
    "* How long will the job run: `--time 2-23`, `--time 06:00:00`. Default is 15 min.\n",
    "* Partition in which to send the job: `--partition debug`, `--partition serial`. Default is parallel on Fidis, depends for Deneb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules\n",
    "\n",
    "Packages are organized hierarchically: Compiler / MPI / blas.\n",
    "\n",
    "    module av(ailable)\n",
    "    module load / unload <module-name>\n",
    "    module spider <name>\n",
    "    module purge\n",
    "    \n",
    "Python: \n",
    "\n",
    "    module load intel\n",
    "    module load python\n",
    "    module list\n",
    "    module load python/2.7.14\n",
    "    module load gcc\n",
    "    module list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter\n",
    "\n",
    "The key is to install the tools using python virtual environments. \n",
    "\n",
    "    module load gcc\n",
    "    module load python\n",
    "    \n",
    "Create virtual environment:\n",
    "\n",
    "    virtualenv --system-site-packages opt/$SYS_TYPE/venv-gcc\n",
    "    \n",
    "Activate it :\n",
    "\n",
    "    source opt/$SYS_TYPE/venv-gcc/bin/activate\n",
    "\n",
    "Install jupyter and ipyparallel\n",
    "\n",
    "    pip install jupyter ipyparallel\n",
    "    \n",
    "Running IPython\n",
    "\n",
    "    Sinteract\n",
    "    source opt/$SYS_TYPE/venv-gcc/bin/activate\n",
    "    ipython\n",
    "\n",
    "Running jupyter: more complicated, we need to launch the server on the login node but make computations on a compute node. That's why we installed ipyparallel. After loading the virtual environment, we use ipcluster to start worker engines on the nodes:\n",
    "\n",
    "    # First find the name of the account\n",
    "    sacctmgr -Pn show assoc where user=$USER format=account\n",
    "    \n",
    "    # Then run \n",
    "    ipcluster start --init --profile=default --ip=\"*\" -n=<ntasks> --engines=Slurm --SlurmEngineSetLauncher.timelimit=<timelimit> --SlurmEngineSetLauncher.queue=<partition> --SlurmEngineSetLauncher.account=<account> &\n",
    "\n",
    "Run jupyter notebook on the login node:\n",
    "\n",
    "    jupyter notebook --ip=\"$(hostname -s).epfl.ch\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Copy the examples into the working directory : \n",
    "\n",
    "    cp -r /scratch/examples/using-the-clusters\n",
    "    \n",
    "## Exercise 1\n",
    "\n",
    "Open `ex1.sh` with an editor. \n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH --workdir /scratch/<put-your-username-here>\n",
    "#SBATCH --nodes 1\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 1\n",
    "#SBATCH --mem 1G\n",
    "#SBATCH --account <put-your-account-here>\n",
    "#SBATCH --reservation using\n",
    "sleep 10\n",
    "echo \"hello from $(hostname)\"\n",
    "sleep 10\n",
    "```\n",
    "\n",
    "Submit the job: `sbatch ex1.sh` and **remember the job ID** displayed. See the output:\n",
    "\n",
    "    cat /scratch/<username>/slurm-ID_XXX.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH --workdir /scratch/<username>\n",
    "#SBATCH --nodes 1\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 28\n",
    "#SBATCH --mem 120G\n",
    "#SBATCH --time 00:30:00\n",
    "#SBATCH --account <your account>\n",
    "#SBATCH --reservation intro2clusters\n",
    "cd /scratch/examples/linpack/\n",
    "./runme_xeon64\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "Use module files\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 4\n",
    "#SBATCH --nodes 1\n",
    "#SBATCH --mem 16G\n",
    "#SBATCH --time 00:15:00\n",
    "#SBATCH --account <your account>\n",
    "#SBATCH --reservation using\n",
    "echo STARTING AT $(date)\n",
    "module purge\n",
    "module load matlab\n",
    "matlab -nodesktop -nojvm -r mymfile\n",
    "echo FINISHED AT $(date)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
